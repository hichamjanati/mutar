{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nHyperparameters of Dirty models\n===============================\n\nThe aim of this example is to show how Dirty models change with the choice\nof their tuning hyperparameters.\n\n`DirtyModel` estimates a set of sparse coefficients for multiple regression\nmodels that share a fraction of non-zero features. It is a generalization of\nThe `GroupLasso` estimator. It also takes a 3D `X (n_tasks, n_samples,\nn_features)` and a 2D `y (n_tasks, n_samples)`.\n\nDirtyModel solves the optimization problem::\n\n\n        (1 / (2 * n_samples)) * ||Y - X(W_1 + W_2)||^2_Fro + alpha * ||W_1||_21\n        + beta * ||W_2||_1\n\nWhere::\n\n        ||W||_21 = \\sum_i \\sqrt{\\sum_j w_ij^2}\n\ni.e. the sum of norm of each row. and::\n\n        ||W||_1 = \\sum_i \\sum_j |w_ij|\n\nSome choices of alpha and beta eventually cancel out W_1 or W_2 entirely.\nThe optimality condition of the optimization problem above leads to:\n\n\n\\begin{align}if \\alpha \\leq \\|X^\\top y\\|_{\\infty\\infty} / n\\_samples\\end{align}\n\nand:\n\n\\begin{align}\\beta \\leq \\|X^\\top y\\|_{2\\infty} / n\\_samples\\end{align}\n\nThen we have the sufficient conditions:\n\n\\begin{align}(1) \\quad \\beta \\geq \\alpha \\Rightarrow W_2 = 0 \\newline\n\n    (2) \\quad \\beta \\leq \\frac{\\alpha}{\\sqrt{n\\_tasks}} \\Rightarrow\n    W_1 = 0\\end{align}\n\n\n(1) leads to a Group Lasso estimator, (2) leads to an independent Lasso with\nthe same beta for all tasks.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Hicham Janati (hicham.janati@inria.fr)\n#\n# License: BSD (3-clause)\n\nimport numpy as np\n\nfrom mutar import DirtyModel\n\nfrom matplotlib import pyplot as plt\nfrom matplotlib.patches import Patch\nfrom matplotlib.lines import Line2D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate multi-task data\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rng = np.random.RandomState(42)\nn_tasks, n_samples, n_features = 5, 20, 50\nX = rng.randn(n_tasks, n_samples, n_features)\n\n# generate random coefficients and make it sparse\n# select support\nsupport = rng.rand(n_features, n_tasks) > 0.95\ncoef = support * rng.randn(n_features, n_tasks)\n\n# make features 0, 2, 4 and 6 shared\ncoef[:7:2] = rng.randn(4, n_tasks)\n\ny = np.array([x.dot(c) for x, c in zip(X, coef.T)])\n\n# add noise\ny += 0.25 * np.std(y) + rng.randn(n_tasks, n_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create a grid of hyperparameters\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "xty = np.array([xx.T.dot(yy) for xx, yy in zip(X, y)])\nbeta_max = abs(xty).max() / n_samples\nalpha_max = np.linalg.norm(xty, axis=0).max() / n_samples\nalphas = np.linspace(0.02, 1.1, 40) * alpha_max\nbetas = np.linspace(0.02, 1.1, 40) * beta_max\n\nalphas_mesh, betas_mesh = np.meshgrid(alphas, alphas)\nalphas_mesh = alphas_mesh.flatten()\nbetas_mesh = betas_mesh.flatten()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For each (alpha, beta) we check if W_1 = 0 or W_2 = 0\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "type_of_model = []\nfor alpha, beta in zip(alphas_mesh, betas_mesh):\n    dirty = DirtyModel(alpha=alpha, beta=beta)\n    dirty.fit(X, y)\n    W1 = abs(dirty.coef_shared_).max()\n    W2 = abs(dirty.coef_specific_).max()\n    if W1 and not W2:\n        type_of_model.append(0)\n    elif W2 and not W1:\n        type_of_model.append(1)\n    elif W1 and W2:\n        type_of_model.append(2)\n    else:\n        type_of_model.append(3)\ntype_of_model = np.array(type_of_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot nature of model depending on hyperparameters\nTo benefit from the partial overlap offered by Dirty models, we should\npick alpha, beta in the gold area\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# We create the legend manually\npatch_colors = [\"indianred\", \"cornflowerblue\", \"gold\", \"black\"]\npatch_names = [\"Group Lasso\", \"Ind Lasso\", \"Dirty (strict)\", \"All Zeros\"]\nline_colors = [\"limegreen\", \"cyan\", \"black\", \"orange\"]\nline_names = [r\"$\\beta = \\alpha$\",\n              r\"$\\beta = \\frac{\\alpha}{\\sqrt{n\\_tasks}}$\",\n              r\"$\\beta = \\beta_{max}$\",\n              r\"$\\alpha = \\alpha_{max}$\"]\npatches = [Patch(color=c, label=name)\n           for c, name in zip(patch_colors, patch_names)]\nlines = [Line2D([0], [0], color=c, lw=3, ls=\"--\", label=name)\n         for c, name in zip(line_colors, line_names)]\nlegend_handles = patches + lines\n\n# We plot the type of each model\ncolors = np.array(patch_colors)[type_of_model]\nf, ax = plt.subplots(1, 1, figsize=(8, 6))\nax.scatter(alphas_mesh / alpha_max, betas_mesh / beta_max, color=colors,\n           alpha=0.5)\nax.plot(alphas / alpha_max, alphas / beta_max, color=line_colors[0], lw=4,\n        ls=\"--\")\nax.plot(alphas / alpha_max, alphas / ((n_tasks ** 0.5) * beta_max),\n        color=line_colors[1], lw=4, ls=\"--\")\nax.hlines(1., xmin=0.02, xmax=1.0, color=\"black\")\nax.vlines(1., ymin=0.02, ymax=1.0, color=\"orange\")\n\nax.set_xlabel(r\"$\\alpha / \\alpha_{max}$\")\nax.set_ylabel(r\"$\\beta / \\beta_{max}$\")\nax.legend(handles=legend_handles, loc=2, ncol=4, bbox_to_anchor=[0.05, 1.18],\n          labelspacing=2., fontsize=10, frameon=False)\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}